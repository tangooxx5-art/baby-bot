import os
import json
import tempfile
import logging
import threading

from flask import Flask, request, abort
from dotenv import load_dotenv

load_dotenv()

app = Flask(__name__)

# è¨­å®š logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get('LINE_CHANNEL_ACCESS_TOKEN', '')
LINE_CHANNEL_SECRET = os.environ.get('LINE_CHANNEL_SECRET', '')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY', '')

# å»¶é²åˆå§‹åŒ–
line_configuration = None
line_handler = None

# å¿«å–åµæ¸¬åˆ°çš„æ¨¡å‹åç¨±
_cached_model_name = None


def get_line_config():
    global line_configuration, line_handler
    if line_configuration is None:
        from linebot.v3.messaging import Configuration
        from linebot.v3 import WebhookHandler
        line_configuration = Configuration(access_token=LINE_CHANNEL_ACCESS_TOKEN)
        line_handler = WebhookHandler(LINE_CHANNEL_SECRET)
        _register_handlers()
    return line_configuration, line_handler


def _register_handlers():
    """è¨»å†Š LINE webhook äº‹ä»¶è™•ç†å™¨"""
    from linebot.v3.webhooks import MessageEvent, ImageMessageContent

    @line_handler.add(MessageEvent, message=ImageMessageContent)
    def handle_image_message(event):
        user_id = event.source.user_id
        message_id = event.message.id
        reply_token = event.reply_token
        thread = threading.Thread(
            target=_process_image_async,
            args=(user_id, message_id, reply_token)
        )
        thread.start()


def _get_best_model(genai):
    """è‡ªå‹•åµæ¸¬æœ€ä½³å¯ç”¨çš„ Gemini æ¨¡å‹ï¼ˆä¸å‘¼å« list_models ä»¥ç¯€çœé…é¡ï¼‰"""
    global _cached_model_name
    if _cached_model_name:
        return _cached_model_name

    # ä¾åå¥½é †åºå˜—è©¦ï¼Œç¬¬ä¸€å€‹èƒ½ç”¨çš„å°±å¿«å–
    candidates = [
        'gemini-2.0-flash',
        'gemini-2.0-pro',
        'gemini-1.5-flash',
        'gemini-1.5-pro',
        'gemini-pro',
    ]

    for name in candidates:
        try:
            model = genai.GenerativeModel(name)
            # ç”¨æœ€è¼•é‡çš„æ–¹å¼æ¸¬è©¦æ¨¡å‹æ˜¯å¦å­˜åœ¨
            model.count_tokens("test")
            _cached_model_name = name
            logger.info(f"Auto-detected model: {name}")
            return _cached_model_name
        except Exception as e:
            logger.info(f"Model {name} not available: {e}")
            continue

    # å…¨éƒ¨å¤±æ•—å°±ç”¨é è¨­
    _cached_model_name = 'gemini-2.0-flash'
    logger.warning(f"All model checks failed, defaulting to {_cached_model_name}")
    return _cached_model_name


@app.route("/", methods=['GET'])
def health_check():
    """å¥åº·æª¢æŸ¥è·¯ç”±"""
    return "Baby Bot is running! ğŸ¼"


@app.route("/callback", methods=['POST'])
def callback():
    from linebot.v3.exceptions import InvalidSignatureError

    signature = request.headers.get('X-Line-Signature', '')
    body = request.get_data(as_text=True)
    logger.info("Request body: " + body)

    _, handler = get_line_config()

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        logger.error("Invalid signature.")
        abort(400)
    except Exception as e:
        logger.error(f"Error in callback handler: {e}", exc_info=True)

    return 'OK'


def _process_image_async(user_id, message_id, reply_token):
    """åœ¨èƒŒæ™¯è™•ç†åœ–ç‰‡ â€” ä½¿ç”¨ push message å›å‚³çµæœï¼ˆä¸å— reply token æ™‚é™é™åˆ¶ï¼‰"""
    import google.generativeai as genai
    from linebot.v3.messaging import (
        ApiClient,
        MessagingApi,
        MessagingApiBlob,
        ReplyMessageRequest,
        PushMessageRequest,
        TextMessage,
        FlexMessage,
        FlexContainer
    )

    config, _ = get_line_config()
    genai.configure(api_key=GEMINI_API_KEY)

    temp_file_path = None

    try:
        # 1. å–å¾—åœ–ç‰‡å…§å®¹
        logger.info(f"[1/4] Downloading image: {message_id}")
        with ApiClient(config) as api_client:
            line_bot_blob_api = MessagingApiBlob(api_client)
            message_content = line_bot_blob_api.get_message_content(message_id)

        # å°‡åœ–ç‰‡å­˜å…¥æš«å­˜æª”
        with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tf:
            if isinstance(message_content, bytes):
                tf.write(message_content)
            elif hasattr(message_content, 'read'):
                tf.write(message_content.read())
            elif hasattr(message_content, 'content'):
                tf.write(message_content.content)
            else:
                tf.write(bytes(message_content))
            temp_file_path = tf.name

        file_size = os.path.getsize(temp_file_path)
        logger.info(f"[2/4] Image saved: {temp_file_path} ({file_size} bytes)")

        if file_size == 0:
            raise ValueError("Downloaded image is empty (0 bytes)")

        # 2. ä¸Šå‚³åœ–ç‰‡è‡³ Gemini API ä¸¦åˆ†æï¼ˆè‡ªå‹•åµæ¸¬æ¨¡å‹ï¼‰
        logger.info("[3/4] Uploading to Gemini and analyzing...")
        sample_file = genai.upload_file(path=temp_file_path, display_name="Ultrasound")
        model_name = _get_best_model(genai)
        logger.info(f"Using model: {model_name}")
        model = genai.GenerativeModel(model_name)

        prompt = """
        è«‹ä½œç‚ºä¸€åã€Œæš–å¿ƒå­•æœŸåŠ©ç†ã€ï¼Œè™•ç†å‚³å…¥çš„å½±åƒï¼š
        - OCR æå–ï¼šè¾¨è­˜ GA (é€±æ•¸)ã€EFW (é«”é‡)ã€EDD (é ç”¢æœŸ)ã€‚
        - èªå¢ƒç”Ÿæˆï¼š
          1. ä½¿ç”¨ã€Œç¬¬ä¸€äººç¨±å¯¶å¯¶èªæ°£ã€ï¼ˆä¾‹å¦‚ï¼šåª½å’ªï¼Œæˆ‘ä»Šå¤©...ï¼‰ã€‚
          2. å°‡é‡é‡èˆ‡æ°´æœ/é£Ÿç‰©å°æ¯”ï¼ˆå¦‚ï¼š200g = ä¸€é¡†å¤§è˜‹æœï¼‰ã€‚
          3. åµæ¸¬ç…§ç‰‡å…§å®¹ï¼ˆè‹¥æ˜¯ 3D è‡‰éƒ¨ï¼Œç¨±è®šé¼»å­æˆ–å˜´å·´ï¼›è‹¥æ˜¯é»‘ç™½ 2Dï¼Œå¼·èª¿å¿ƒè·³èˆ‡æˆé•·ï¼‰ã€‚
        - è¼¸å‡ºé™åˆ¶ï¼šåƒ…è¼¸å‡º JSON æ ¼å¼ï¼ŒåŒ…å« `weeks`, `weight_status`, `message`, `suggested_color`ã€‚
        è«‹å‹¿è¼¸å‡ºä»»ä½• markdown æ¨™è¨˜ï¼Œç›´æ¥è¼¸å‡ºä¹¾æ·¨çš„ JSON å­—ä¸²ã€‚
        """

        response = model.generate_content([sample_file, prompt])

        # æ¸…ç† Gemini æš«å­˜
        try:
            genai.delete_file(sample_file.name)
        except Exception:
            pass

        # 3. è§£æ JSON
        response_text = response.text.strip()
        logger.info(f"Gemini raw response: {response_text[:200]}")

        if response_text.startswith("```json"):
            response_text = response_text[7:]
        if response_text.startswith("```"):
            response_text = response_text[3:]
        if response_text.endswith("```"):
            response_text = response_text[:-3]

        try:
            result_json = json.loads(response_text.strip())
        except json.JSONDecodeError as e:
            logger.error(f"JSON parse failed: {e}, raw: {response_text[:300]}")
            result_json = {
                "weeks": "?",
                "message": response_text[:300] if response_text else "åª½å’ªå¥½ï¼æˆ‘çœ‹ä¸å¤ªæ¸…æ¥šï¼Œå¯ä»¥å†å‚³ä¸€æ¬¡æ¸…æ™°çš„ç…§ç‰‡å—ï¼Ÿ",
                "weight_status": "æœªçŸ¥",
                "suggested_color": "#ffcccc"
            }

        # 4. çµ„è£ Flex Message ä¸¦å›å‚³
        logger.info("[4/4] Sending Flex Message...")
        flex_dict = {
            "type": "bubble",
            "header": {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    {
                        "type": "text",
                        "text": f"ç¬¬ {result_json.get('weeks', '?')} é€±æˆé•·ç´€éŒ„",
                        "weight": "bold",
                        "size": "xl",
                        "color": "#ff7fa8"
                    }
                ]
            },
            "body": {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    {
                        "type": "text",
                        "text": result_json.get('message', 'åª½å’ªå¥½ï¼Œæˆ‘æ˜¯å¯¶å¯¶ï¼'),
                        "wrap": True,
                        "size": "md"
                    }
                ]
            }
        }

        flex_container = FlexContainer.from_dict(flex_dict)
        flex_message = FlexMessage(alt_text="å¯¶å¯¶çš„è¶…éŸ³æ³¢ç´€éŒ„ä¾†å›‰ï¼", contents=flex_container)

        with ApiClient(config) as api_client:
            line_bot_api = MessagingApi(api_client)

            # å…ˆå˜—è©¦ replyï¼ˆå¦‚æœ token é‚„æœ‰æ•ˆï¼‰
            try:
                line_bot_api.reply_message(
                    ReplyMessageRequest(
                        reply_token=reply_token,
                        messages=[flex_message]
                    )
                )
                logger.info("Reply message sent successfully!")
            except Exception as reply_err:
                logger.warning(f"Reply failed ({reply_err}), using push message instead")
                line_bot_api.push_message(
                    PushMessageRequest(
                        to=user_id,
                        messages=[flex_message]
                    )
                )
                logger.info("Push message sent successfully!")

    except Exception as e:
        logger.error(f"Error processing image: {e}", exc_info=True)
        try:
            with ApiClient(config) as api_client:
                line_bot_api = MessagingApi(api_client)
                line_bot_api.push_message(
                    PushMessageRequest(
                        to=user_id,
                        messages=[TextMessage(text=f"æŠ±æ­‰ï¼Œè™•ç†ç…§ç‰‡æ™‚å‡ºäº†é»å•é¡Œï¼Œè«‹ç¨å¾Œå†è©¦ ğŸ™\néŒ¯èª¤: {str(e)[:100]}")]
                    )
                )
        except Exception as push_err:
            logger.error(f"Failed to send error message: {push_err}")
    finally:
        if temp_file_path and os.path.exists(temp_file_path):
            os.remove(temp_file_path)


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8000)
